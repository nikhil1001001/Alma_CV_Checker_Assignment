{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0yWIuBuMyp8OnC8Cqpo17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikhil1001001/Alma_CV_Checker_Assignment/blob/main/Alma_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kCXarigwUi2b"
      },
      "outputs": [],
      "source": [
        "!pip install uvicorn beautifulsoup4 requests faiss-cpu sentence-transformers python-docx pdfplumber -q"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Web Scraping"
      ],
      "metadata": {
        "id": "phwVL0xcU2xx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import json\n",
        "\n",
        "# List of URLs to scrape\n",
        "URLS = [\n",
        "    \"https://www.uscis.gov/working-in-the-united-states/temporary-workers/o-1-visa-individuals-with-extraordinary-ability-or-achievement\",\n",
        "    \"https://www.uscis.gov/policy-manual/volume-2-part-m#\",\n",
        "    \"https://www.tryalma.com/o-1a-visa-guide\"\n",
        "]\n",
        "\n",
        "def scrape_o1a_criteria():\n",
        "    criteria = []\n",
        "\n",
        "    for url in URLS:\n",
        "        response = requests.get(url)\n",
        "        if response.status_code != 200:\n",
        "            print(f\"Failed to fetch {url}\")\n",
        "            continue\n",
        "\n",
        "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
        "\n",
        "        # Find relevant sections (Modify selectors based on actual webpage structure)\n",
        "        sections = soup.find_all(\"h3\")  # Assuming criteria are under <h3> tags\n",
        "        if not sections:\n",
        "            sections = soup.find_all(\"p\")  # Fallback to paragraphs if <h3> not found\n",
        "\n",
        "        for section in sections:\n",
        "            text = section.get_text(strip=True)\n",
        "            criteria.append(text)\n",
        "\n",
        "    # Save extracted criteria to JSON\n",
        "    with open(\"o1a_criteria.json\", \"w\") as f:\n",
        "        json.dump(criteria, f, indent=4)\n",
        "\n",
        "    print(f\"Scraped {len(criteria)} O-1A criteria items from {len(URLS)} websites.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    scrape_o1a_criteria()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIZZ5QlMXUE1",
        "outputId": "3e042839-5899-438d-d449-9d205ffee0b0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 125 O-1A criteria items from 3 websites.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import faiss\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load the scraped criteria from JSON\n",
        "with open(\"o1a_criteria.json\", \"r\") as f:\n",
        "    o1a_criteria = json.load(f)\n",
        "\n",
        "# Load the Sentence Transformer model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")  # Fast and lightweight model\n",
        "\n",
        "# Convert criteria into embeddings\n",
        "embeddings = model.encode(o1a_criteria)\n",
        "\n",
        "# Store in FAISS\n",
        "dimension = embeddings.shape[1]\n",
        "index = faiss.IndexFlatL2(dimension)  # L2 distance index\n",
        "index.add(np.array(embeddings))  # Add embeddings to FAISS index\n",
        "\n",
        "# Save FAISS index\n",
        "faiss.write_index(index, \"o1a_faiss.index\")\n",
        "\n",
        "# Save criteria mapping\n",
        "with open(\"o1a_criteria_list.json\", \"w\") as f:\n",
        "    json.dump(o1a_criteria, f, indent=4)\n",
        "\n",
        "print(f\"Stored {len(o1a_criteria)} criteria embeddings in FAISS.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5KfHM6jYw6B",
        "outputId": "37a09564-d873-4bb4-a6ba-ac3c561fa80b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stored 125 criteria embeddings in FAISS.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "import json\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load FAISS index and criteria\n",
        "index = faiss.read_index(\"o1a_faiss.index\")\n",
        "with open(\"o1a_criteria_list.json\", \"r\") as f:\n",
        "    o1a_criteria = json.load(f)\n",
        "\n",
        "# Load embedding model\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "def match_criteria(cv_text, top_k=5):\n",
        "    \"\"\"Matches CV content against O-1A visa criteria using semantic search.\"\"\"\n",
        "\n",
        "    # Encode CV text\n",
        "    cv_embedding = model.encode([cv_text])\n",
        "\n",
        "    # Search in FAISS\n",
        "    distances, indices = index.search(np.array(cv_embedding), top_k)\n",
        "\n",
        "    # Get matching criteria\n",
        "    matched_criteria = [o1a_criteria[idx] for idx in indices[0]]\n",
        "\n",
        "    return matched_criteria\n"
      ],
      "metadata": {
        "id": "7S6VmW2wY4j1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdfplumber\n",
        "import docx\n",
        "\n",
        "def extract_text(file_path):\n",
        "    \"\"\"Extract text from PDF or DOCX files.\"\"\"\n",
        "    text = \"\"\n",
        "\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        with pdfplumber.open(file_path) as pdf:\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text() + \"\\n\"\n",
        "\n",
        "    elif file_path.endswith(\".docx\"):\n",
        "        doc = docx.Document(file_path)\n",
        "        for para in doc.paragraphs:\n",
        "            text += para.text + \"\\n\"\n",
        "\n",
        "    return text.strip()\n"
      ],
      "metadata": {
        "id": "RId6SKHFZYZO"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio -q\n"
      ],
      "metadata": {
        "id": "lGCfDJSEZjPS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load Sentence Transformer model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define O-1A visa criteria and their descriptions\n",
        "o1a_criteria = {\n",
        "    \"Awards\": \"The applicant must have received nationally or internationally recognized prizes or awards.\",\n",
        "    \"Membership\": \"The applicant must be a member of associations that require outstanding achievements.\",\n",
        "    \"Press\": \"There must be published material about the applicant in major media.\",\n",
        "    \"Judging\": \"The applicant must have served as a judge of the work of others in their field.\",\n",
        "    \"Original Contribution\": \"The applicant must have made original contributions of major significance.\",\n",
        "    \"Scholarly Articles\": \"The applicant must have authored scholarly articles in professional journals.\",\n",
        "    \"Critical Employment\": \"The applicant must have been employed in a critical or essential capacity.\",\n",
        "    \"High Remuneration\": \"The applicant must have commanded a high salary compared to others in the field.\"\n",
        "}\n",
        "\n",
        "# Convert O-1A criteria into embeddings\n",
        "criteria_embeddings = {key: model.encode(value, convert_to_tensor=True) for key, value in o1a_criteria.items()}\n",
        "\n",
        "# Function to analyze CV and match with O-1A criteria\n",
        "def analyze_cv(cv_text):\n",
        "    # Convert CV text into an embedding\n",
        "    cv_embedding = model.encode(cv_text, convert_to_tensor=True)\n",
        "\n",
        "    criteria_results = {}\n",
        "    matched_count = 0\n",
        "\n",
        "    for criterion, embedding in criteria_embeddings.items():\n",
        "        similarity_score = util.pytorch_cos_sim(cv_embedding, embedding).item()\n",
        "\n",
        "        # Define a similarity threshold (adjustable)\n",
        "        if similarity_score > 0.5:\n",
        "            criteria_results[criterion] = \"✔ Found\"\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            criteria_results[criterion] = \"❌ Not Found\"\n",
        "\n",
        "    # Assign a rating based on the number of matched criteria\n",
        "    rating = \"Low\" if matched_count <= 3 else \"Medium\" if matched_count <= 6 else \"High\"\n",
        "\n",
        "    return criteria_results, rating\n",
        "\n",
        "# Define the Gradio UI\n",
        "interface = gr.Interface(\n",
        "    fn=analyze_cv,\n",
        "    inputs=gr.Textbox(lines=10, placeholder=\"Paste CV text here...\"),\n",
        "    outputs=[gr.JSON(label=\"Matched Criteria\"), gr.Text(label=\"Visa Qualification Rating\")],\n",
        "    title=\"O-1A Visa Qualification Checker\",\n",
        "    description=\"Upload a CV and check how well it matches the O-1A visa requirements.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "IS584HlZa5va",
        "outputId": "7705c1cc-6c28-4eae-bc66-cce075488383"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://25102a1dd2740121a3.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://25102a1dd2740121a3.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2 -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-OmdgpEnbIUQ",
        "outputId": "a503b3b7-6d3f-440f-9210-0eab1b29d130"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/232.6 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import torch\n",
        "import PyPDF2  # Import PyPDF2 for PDF text extraction\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "# Load Sentence Transformer model\n",
        "model = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
        "\n",
        "# Define O-1A visa criteria and their descriptions\n",
        "o1a_criteria = {\n",
        "    \"Awards\": \"The applicant must have received nationally or internationally recognized prizes or awards.\",\n",
        "    \"Membership\": \"The applicant must be a member of associations that require outstanding achievements.\",\n",
        "    \"Press\": \"There must be published material about the applicant in major media.\",\n",
        "    \"Judging\": \"The applicant must have served as a judge of the work of others in their field.\",\n",
        "    \"Original Contribution\": \"The applicant must have made original contributions of major significance.\",\n",
        "    \"Scholarly Articles\": \"The applicant must have authored scholarly articles in professional journals.\",\n",
        "    \"Critical Employment\": \"The applicant must have been employed in a critical or essential capacity.\",\n",
        "    \"High Remuneration\": \"The applicant must have commanded a high salary compared to others in the field.\"\n",
        "}\n",
        "\n",
        "# Convert O-1A criteria into embeddings\n",
        "criteria_embeddings = {key: model.encode(value, convert_to_tensor=True) for key, value in o1a_criteria.items()}\n",
        "\n",
        "# Function to extract text from PDF using PyPDF2\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    text = \"\"\n",
        "    with open(pdf_path, \"rb\") as file:\n",
        "        pdf_reader = PyPDF2.PdfReader(file)\n",
        "        for page in pdf_reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    return text\n",
        "\n",
        "# Function to analyze CV and match with O-1A criteria\n",
        "def analyze_cv(pdf_file):\n",
        "    # Extract text from the uploaded PDF\n",
        "    cv_text = extract_text_from_pdf(pdf_file.name)\n",
        "\n",
        "    # Convert CV text into an embedding\n",
        "    cv_embedding = model.encode(cv_text, convert_to_tensor=True)\n",
        "\n",
        "    criteria_results = {}\n",
        "    matched_count = 0\n",
        "\n",
        "    for criterion, embedding in criteria_embeddings.items():\n",
        "        similarity_score = util.pytorch_cos_sim(cv_embedding, embedding).item()\n",
        "\n",
        "        # Define a similarity threshold (adjustable)\n",
        "        if similarity_score > 0.5:\n",
        "            criteria_results[criterion] = \"✔ Found\"\n",
        "            matched_count += 1\n",
        "        else:\n",
        "            criteria_results[criterion] = \"❌ Not Found\"\n",
        "\n",
        "    # Assign a rating based on the number of matched criteria\n",
        "    rating = \"Low\" if matched_count <= 3 else \"Medium\" if matched_count <= 6 else \"High\"\n",
        "\n",
        "    return criteria_results, rating\n",
        "\n",
        "# Define the Gradio UI with PDF upload\n",
        "interface = gr.Interface(\n",
        "    fn=analyze_cv,\n",
        "    inputs=gr.File(label=\"Upload CV (PDF only)\"),\n",
        "    outputs=[gr.JSON(label=\"Matched Criteria\"), gr.Text(label=\"Visa Qualification Rating\")],\n",
        "    title=\"O-1A Visa Qualification Checker\",\n",
        "    description=\"Upload a CV in PDF format and check how well it matches the O-1A visa requirements.\"\n",
        ")\n",
        "\n",
        "# Launch Gradio\n",
        "interface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "I5-p6XP2b4-J",
        "outputId": "01840ade-dd84-48bb-b8e4-c320bb1ad500"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://184e471db3a58a30ab.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://184e471db3a58a30ab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    }
  ]
}